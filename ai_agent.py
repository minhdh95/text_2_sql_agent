import os
from dotenv import load_dotenv
import gradio as gr
from groq import Groq
from sqlalchemy import create_engine, text

# ===== LOAD ENV =====
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# ===== INIT GROQ =====
client = Groq(api_key=GROQ_API_KEY)

DB_URI = "sqlite:///my_data.db"   # ƒë√∫ng v·ªõi file b·∫°n ƒëang c√≥
engine = create_engine(DB_URI)
def get_db_schema() -> str:
    schema = ""
    with engine.connect() as conn:
        tables = conn.execute(
            text("SELECT name FROM sqlite_master WHERE type='table'")
        ).fetchall()

        for (table_name,) in tables:
            schema += f"\nTable {table_name} (\n"
            columns = conn.execute(
                text(f"PRAGMA table_info({table_name})")
            ).fetchall()

            for col in columns:
                schema += f"  {col[1]} {col[2]},\n"
            schema += ")\n"

    return schema


# ===== TEXT ‚Üí SQL =====
def text_to_sql(question: str) -> str:
    schema = get_db_schema()   # üëà l·∫•y schema th·∫≠t

    prompt = f"""
B·∫°n l√† chuy√™n gia SQL.

Schema database:
{schema}

Vi·∫øt c√¢u SQL CH√çNH X√ÅC ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.
Ch·ªâ tr·∫£ v·ªÅ SQL thu·∫ßn, KH√îNG markdown, KH√îNG gi·∫£i th√≠ch.

C√¢u h·ªèi:
{question}
"""

    res = client.chat.completions.create(
        model="meta-llama/llama-4-scout-17b-16e-instruct",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )

    return res.choices[0].message.content.strip()



# ===== RUN SQL =====
def run_sql(sql: str):
    with engine.connect() as conn:
        result = conn.execute(text(sql))
        rows = result.fetchall()
        columns = result.keys()
    return columns, rows


# ===== RESULT ‚Üí NG√îN NG·ªÆ T·ª∞ NHI√äN =====
def explain_result(question, columns, rows):
    prompt = f"""
Ng∆∞·ªùi d√πng h·ªèi:
{question}

K·∫øt qu·∫£ truy v·∫•n:
C·ªôt: {list(columns)}
D·ªØ li·ªáu: {rows}

H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, d·ªÖ hi·ªÉu, t·ª± nhi√™n nh∆∞ ng∆∞·ªùi th·∫≠t.
"""

    res = client.chat.completions.create(
        model="meta-llama/llama-4-scout-17b-16e-instruct",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )

    return res.choices[0].message.content

def clean_sql(sql: str) -> str:
    sql = sql.strip()

    # X√≥a markdown ```sql ... ```
    if sql.startswith("```"):
        sql = sql.replace("```sql", "")
        sql = sql.replace("```", "")
        sql = sql.strip()

    return sql

# ===== PIPELINE CH√çNH =====
def handle_query(question):
    try:
        raw_sql = text_to_sql(question)
        sql = clean_sql(raw_sql)

        cols, rows = run_sql(sql)
        answer = explain_result(question, cols, rows)

        return answer, sql

    except Exception as e:
        return f"‚ùå L·ªói: {e}", ""



# ===== GRADIO UI =====
demo = gr.Interface(
    fn=handle_query,
    inputs=gr.Textbox(lines=3, label="üí¨ Nh·∫≠p c√¢u h·ªèi"),
    outputs=[
        gr.Textbox(label="‚úÖ C√¢u tr·∫£ l·ªùi"),
        gr.Textbox(label="üìÑ SQL ƒë∆∞·ª£c sinh ra"),
    ],
    title="üß† AI Text-to-SQL Assistant",
    description="H·ªèi b·∫±ng ti·∫øng Vi·ªát ho·∫∑c ti·∫øng Anh. AI s·∫Ω truy v·∫•n DB v√† tr·∫£ l·ªùi.",
)

if __name__ == "__main__":
    demo.launch(server_port=7861)
